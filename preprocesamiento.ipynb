{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LIMPIEZA DE DATOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import missingno as msno \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE FICHEROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARPETA_DATOS_ORIGINALES = 'Datos/Originales/'\n",
    "df_sabi_1= pd.read_excel(os.path.join(CARPETA_DATOS_ORIGINALES, 'df_sabi_modif_1.xlsx'))\n",
    "df_sabi_2= pd.read_excel(os.path.join(CARPETA_DATOS_ORIGINALES, 'df_sabi_modif_2_new.xlsx'))\n",
    "df_dealroom= pd.read_excel(os.path.join(CARPETA_DATOS_ORIGINALES, 'df_dealroom_modif.xlsx'))\n",
    "df_sabi_3= pd.read_excel(os.path.join(CARPETA_DATOS_ORIGINALES, 'df_sabi_parte3.xlsx'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZACIi“N DE FICHEROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sabi_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sabi_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealroom.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sabi_1.isna().sum())\n",
    "print(df_sabi_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sabi_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sabi_2.isna().sum())\n",
    "print(msno.matrix(df_sabi_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sabi_3.isna().sum())\n",
    "print(msno.matrix(df_sabi_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERSION DE VALORES Y CREACION DE VARIABLES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### df_sabi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasamos el n.s. a NaN con applymap\n",
    "df_sabi_2=df_sabi_2.applymap(lambda x: np.nan if x=='n.s.' else x)\n",
    "df_sabi_3=df_sabi_3.applymap(lambda x: np.nan if x=='n.s.' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sabi_2.shape)\n",
    "# se calcula la cantidad de nulos por fila\n",
    "# print(df_sabi_2.isna().sum(axis=1)[df_sabi_2.isna().sum(axis=1)>8])\n",
    "indices_missings= df_sabi_2.isna().sum(axis=1)[df_sabi_2.isna().sum(axis=1)>8].index\n",
    "print(df_sabi_2.iloc[indices_missings,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea columna con numero de missing por fila\n",
    "df_sabi_2['n_missings']= df_sabi_2.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realizan boxplots de las columnas numericas que esti©n mostradas en %.\n",
    "df_sabi_2_porcentaje = df_sabi_2.loc[:, df_sabi_2.columns.str.contains('%')]\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.boxplot(data=df_sabi_2_porcentaje, ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_ylim(-500, 500)\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(100))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### df_sabi_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de df_sabi_3 nos quedamos solo con 4 variables\n",
    "df_sabi_3_final= df_sabi_3[['Codigo_NIF','year', 'Gastos de personal mil EUR', 'Coste medio de los empleados mil']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZACION DE VALORES AUSENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dealroom.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealroom.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se pasa el growth stage a dummy\n",
    "mapping = {'seed': 0, 'early growth': 1, 'late growth': 2}\n",
    "df_dealroom['growth_stage'] = df_dealroom['growth_stage'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se sustituyen las letras con tildes por las letras sin tildes de todas las columnas de df_sabi_2\n",
    "df_sabi_2.columns= df_sabi_2.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "# lo mismo con el resto de dataframes\n",
    "df_sabi_1.columns= df_sabi_1.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_dealroom.columns= df_dealroom.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "df_sabi_3_final.columns= df_sabi_3_final.columns.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlograma de missing values\n",
    "msno.heatmap(df_dealroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnas financieras\n",
    "columnas_financieras= df_sabi_2.columns \n",
    "columnas_financieras= columnas_financieras.append(df_sabi_3_final.columns)\n",
    "columnas_financieras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealroom[df_dealroom['n_empleados_dealroom'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERSION DE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se convierte la primera letra de cada palabra a mayuscula\n",
    "df_dealroom['last_funding_date']= df_dealroom['last_funding_date'].str.capitalize()\n",
    "df_dealroom['first_funding_date']= df_dealroom['first_funding_date'].str.capitalize()\n",
    "# hay un valor de fecha que aparece solo el ai±o, se pasa a formato mes/ai±o\n",
    "indice = df_dealroom[df_dealroom['last_funding_date']=='2021'].index[0]\n",
    "df_dealroom.at[indice, 'last_funding_date'] = 'Jan/2021'\n",
    "indice = df_dealroom[df_dealroom['first_funding_date']=='2003'].index[0]\n",
    "df_dealroom.at[indice, 'first_funding_date'] = 'Jan/2003'\n",
    "indice = df_dealroom[df_dealroom['first_funding_date']=='2017'].index[0]\n",
    "df_dealroom.at[indice, 'first_funding_date'] = 'Jan/2017'\n",
    "# se pasan las fechas a datetime\n",
    "df_dealroom['last_funding_date']= pd.to_datetime(df_dealroom['last_funding_date'], format='%b/%Y')\n",
    "df_dealroom['first_funding_date']= pd.to_datetime(df_dealroom['first_funding_date'], format='%b/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dealroom['b2b_b2c'].value_counts())\n",
    "print(df_dealroom['b2b_b2c'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se cogen las empresas que el campo b2b_b2c es NaN\n",
    "empresas_b2b_b2c_nan= df_dealroom[df_dealroom['b2b_b2c'].isna()]\n",
    "empresas_b2b_b2c_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se busca si es b2b o b2c a mano y se crea una funcion para automatizarlo\n",
    "lista_empresa_consumer= ['Feelfree Rentals', 'Modfie', 'Worldpats', 'Kimet Sport', 'Puntodis', 'DNA Data' ]\n",
    "lista_empresa_bussines= ['Hub Gasteiz', 'Quevedos Strategic Partners', 'Anbiolab', 'Solid Machine Vision', 'Innovative Hall Media Technologies', 'lorke systems',\n",
    "'Gistek Insurance Solutions', 'VIRTUALWARE', 'Naivan', ]\n",
    "for empresa in lista_empresa_consumer:\n",
    "    df_dealroom.iloc[df_dealroom[df_dealroom['name_dealroom'] == empresa].index[0],13]= 'consumer'\n",
    "for empresa in lista_empresa_bussines:\n",
    "    df_dealroom.iloc[df_dealroom[df_dealroom['name_dealroom'] == empresa].index[0],13]= 'business'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se pasan b2b a 1 en una columna, b2c a 1 en otra, y se dejan los que son ambos a 0\n",
    "df_dealroom['b2b']= df_dealroom['b2b_b2c'].apply(lambda x: 1 if 'business' in x else 0)\n",
    "df_dealroom['b2c']= df_dealroom['b2b_b2c'].apply(lambda x: 1 if 'consumer' in x else 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIi“N DE LOS DATAFRAMES EN UNO išNICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntamos los dos df_sabi\n",
    "df_sabi= pd.merge(df_sabi_1, df_sabi_2, on='Codigo_NIF', how='inner')\n",
    "df_sabi_completo= pd.merge(df_sabi, df_sabi_3_final, on=['Codigo_NIF','year'], how='left')\n",
    "# juntamos este df con el de dealroom\n",
    "df= pd.merge(df_sabi_completo, df_dealroom, on='Codigo_NIF', how='inner')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msno.matrix(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se visualiza de las columnas en las que hay missings en la columna de empleados normal, cuantos missings hay en la de dealroom\n",
    "print(df['Numero empleados'].isna().sum())\n",
    "print(df[df.loc[:,'Numero empleados'].isna()]['n_empleados_dealroom'].isna().sum())\n",
    "# hay 10 valores que no hay en la columna de sabi, pero si en la de dealroom, por lo que se indica\n",
    "df['Numero empleados']= df.loc[:,'Numero empleados'].fillna(df['n_empleados_dealroom'])\n",
    "# Ahora solo quedan 70 valores nulos en la columna de empleados, que son los que no tienen en ninguno de las dos df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se quita la columna de n_empleados_dealroom\n",
    "df= df.drop('n_empleados_dealroom', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_inicial= df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas de creacion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiempo que lleva la empresa en el mercado\n",
    "# Tiempo desde creacion hasta primer round\n",
    "# Tiempo desde primer round hasta ultimo round"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREACION DE NUEVAS VARIABLES EN EL NUEVO DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fecha constitucion']=pd.to_datetime(df['Fecha constitucion'], format='%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se crea una variable para conocer los ai±os que lleva la empresa en el mercado\n",
    "df['Anos en Mercado']= (2023-df['Fecha constitucion'].dt.year)\n",
    "columnas = list(df.columns)\n",
    "columnas.remove('Anos en Mercado')\n",
    "\n",
    "# se altera el orden de las columnas para que los ai±os en el mercado vayan despues de la fecha de constitucion\n",
    "columnas = columnas[:columnas.index(\"Fecha constitucion\")+1] + ['Anos en Mercado'] + columnas[columnas.index(\"Fecha constitucion\")+1:]\n",
    "df = df.reindex(columns=columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot de la valoraciones en 2022.\n",
    "sns.boxplot(y=df['Anos en Mercado'])\n",
    "plt.xlabel('Anos en Mercado', weight='bold')\n",
    "plt.ylabel('', weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revenue models a dummy con sklearn e ignorando los missings\n",
    "df['revenue_models']= df['revenue_models'].fillna('missing')\n",
    "opciones = ['saas', 'missing' ,'manufacturing', 'marketplace & ecommerce']\n",
    "for opcion in opciones:\n",
    "    df[f'revenue_{opcion}']= df['revenue_models'].apply(lambda x: 1 if opcion in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_funding_date']=pd.to_datetime(df['last_funding_date'], format='%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se crea una variable para conocer los ai±os desde que se realizon la ultima financiacion.\n",
    "df['Anos desde ultima financiacion']= (2023-df['last_funding_date'].dt.year)\n",
    "df['Anos desde ultima financiacion'].fillna(0, inplace=True)\n",
    "df['Anos desde ultima financiacion'] = df['Anos desde ultima financiacion'].astype(int)\n",
    "\n",
    "# se altera el orden de las columnas para que los ai±os desde ultima financiacion vayan despues de la fecha de ultima financiacion.\n",
    "columnas = list(df.columns)\n",
    "columnas.remove('Anos desde ultima financiacion')\n",
    "columnas = columnas[:columnas.index('last_funding_date')+1] + ['Anos desde ultima financiacion'] + columnas[columnas.index('last_funding_date')+1:]\n",
    "df = df.reindex(columns=columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se ven cuantas filas tienen missing la columna de last_funding entre las que valuation_2022 no es missing\n",
    "print(df[(df['last_funding'].isna()) & (df['valuation_2022'].notna())].shape)\n",
    "print(df[df['valuation_2022'].notna()].shape)\n",
    "# una de cada 4 empresas que tiene valoracion en 2022 tiene missing en last_funding, asi que estari­a bien imputarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot de la valoraciones en 2022.\n",
    "sns.boxplot(y=df['valuation_2022'])\n",
    "plt.xlabel('Valoracion 2022', weight='bold')\n",
    "plt.ylabel('', weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otras cosas a hacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finanzas= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar columnas con muchos missings (ejemplo: deuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_missings']=df.isna().sum(axis=1)\n",
    "x=pd.DataFrame(df['n_missings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Inmovilizado mil EUR']=df['Inmovilizado mil EUR'].fillna(df['Total activo mil EUR'] - df['Activo circulante mil EUR'])\n",
    "df['Activo circulante mil EUR']=df['Activo circulante mil EUR'].fillna(df['Total activo mil EUR'] - df['Inmovilizado mil EUR'].fillna(0))\n",
    "df['Total activo mil EUR']=df['Total activo mil EUR'].fillna(df['Total pasivo y capital propio mil EUR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df['Activo circulante mil EUR']==df['Activo circulante mil EUR'].fillna(df['Total activo mil EUR'] - df['Inmovilizado mil EUR'])).sum())\n",
    "print((df['Inmovilizado mil EUR']==df['Inmovilizado mil EUR'].fillna(df['Total activo mil EUR'] - df['Activo circulante mil EUR'])).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sabiendo que -> df['Pasivo fijo mil EUR']=df['Pasivo fijo mil EUR'].fillna(df['Acreedores a L. P. mil EUR'].fillna(0)+df['Deudas financieras mil EUR'])\n",
    "a= df['Pasivo liquido mil EUR']== df['Deudas financieras mil EUR'].fillna(0)+df['Acreedores comerciales mil EUR'].fillna(0)\n",
    "print(a.sum())\n",
    "b= df['Activo circulante mil EUR']== df['Existencias mil EUR'].fillna(0)+df['Deudores mil EUR'].fillna(0)+ df['Tesoreria mil EUR'].fillna(0)\n",
    "print(b.sum())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Pasivo fijo mil EUR']-df['Acreedores comerciales mil EUR'] == df['Deudas financieras mil EUR']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Fondos propios mil EUR']=df['Fondos propios mil EUR'].fillna(df['Capital suscrito mil EUR'].fillna(0)+df['Otros fondos propios mil EUR'].fillna(0))\n",
    "df['Pasivo fijo mil EUR']=df['Pasivo fijo mil EUR'].fillna(df['Total pasivo y capital propio mil EUR'].fillna(0)-df['Pasivo liquido mil EUR'].fillna(0)-df['Fondos propios mil EUR'].fillna(0))\n",
    "df['Pasivo liquido mil EUR']=df['Pasivo liquido mil EUR'].fillna(df['Total pasivo y capital propio mil EUR'].fillna(0)-df['Pasivo fijo mil EUR'].fillna(0)-df['Fondos propios mil EUR'].fillna(0))\n",
    "df['Total pasivo']=(df['Pasivo fijo mil EUR']+df['Pasivo liquido mil EUR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputamos numero de empleados con gastos de personal y coste medio por empleado\n",
    "df['Numero empleados']=df['Numero empleados'].fillna(df['Gastos de personal mil EUR']/df['Coste medio de los empleados mil'])\n",
    "df['Coste medio de los empleados mil']=df['Coste medio de los empleados mil'].fillna(df['Gastos de personal mil EUR']/df['Numero empleados'])\n",
    "df['Gastos de personal mil EUR']=df['Gastos de personal mil EUR'].fillna(df['Numero empleados']*df['Coste medio de los empleados mil'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputamos el coste medio de los empleados haciendo una media por sector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Resultado Actividades Ordinarias mil EUR']==df['Result. ordinarios antes Impuestos mil EUR']- df['Impuestos sobre sociedades mil EUR'].fillna(0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realiza estos calculos si alguna de estas columnas es nula, y sustituye el valor nulo por el calculado\n",
    "df['Impuestos sobre sociedades mil EUR']=df['Impuestos sobre sociedades mil EUR'].fillna(df['Result. ordinarios antes Impuestos mil EUR']-df['Resultado Actividades Ordinarias mil EUR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localidad= df['Localidad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar columna forma juridica o forma juridica detallada, lo mismo con estado y estado detallado\n",
    "df= df.drop('Forma juridica detallada', axis=1)\n",
    "df= df.drop('Estado detallado', axis=1)\n",
    "# se quita la columna de n_empleados_dealroom\n",
    "df= df.drop('n_empleados_dealroom', axis=1)\n",
    "# Quitar columnas que no aportan informacion (ejemplo: nombre de la empresa, pagina web, ciudad, etc)\n",
    "df= df.drop('Localidad', axis=1)\n",
    "# quitamos la columna de codigo de consolidacion porque casi todos los valores son de un tipo\n",
    "df= df.drop('Codigo consolidacion', axis=1)\n",
    "# quitamos la columna de estado porque son todos activas\n",
    "df= df.drop('Estado', axis=1)\n",
    "# quitamos tagline \n",
    "df= df.drop('tagline', axis=1)\n",
    "# tambien website\n",
    "df= df.drop('website', axis=1)\n",
    "# profile_url\n",
    "df= df.drop('profile_url', axis=1)\n",
    "# name_dealroom porque ya salen en sabi\n",
    "df= df.drop('name_dealroom', axis=1)\n",
    "# n_missings\n",
    "df= df.drop('n_missings', axis=1)\n",
    "# forma juridica\n",
    "df= df.drop('Forma juridica', axis=1)\n",
    "# company status\n",
    "df= df.drop('company_status', axis=1) # el 95% son operational\n",
    "# b2bc\n",
    "df= df.drop('b2b_b2c', axis=1) # ya hay columnas si es b2b o b2c\n",
    "# revenue models\n",
    "df= df.drop('revenue_models', axis=1) # ya hay columnas dummies\n",
    "# quitamos las fechas\n",
    "df= df.drop('last_funding_date', axis=1)\n",
    "df= df.drop('first_funding_date', axis=1)\n",
    "df= df.drop('Fecha constitucion', axis=1)\n",
    "# resultado de actividades ordinarias porque es igual que resultado del ejercicio\n",
    "df= df.drop('Resultado Actividades Ordinarias mil EUR', axis=1)\n",
    "# quitamos los inmovilizados materiales e inmateriales y nos quedamos con inmovilizado\n",
    "df= df.drop('Inmovilizado material mil EUR', axis=1)\n",
    "df= df.drop('Inmovilizado inmaterial mil EUR', axis=1)\n",
    "# eliminamos existencias y â‚¬ % existencias\n",
    "df= df.drop('Existencias mil EUR', axis=1)\n",
    "df= df.drop('Rotacion de las existencias %', axis=1)\n",
    "# quitamos dotaciones para amortizaciones de inmovilizado\n",
    "df= df.drop('Dotaciones para amortiz. de inmovil. mil EUR', axis=1)\n",
    "# gastos financieros\n",
    "df= df.drop('Gastos financieros y gastos asimilados mil EUR', axis=1)\n",
    "# free capital por ser todo ceros\n",
    "df= df.drop('Free capital mil EUR', axis=1)\n",
    "# otros fondos propios\n",
    "df= df.drop('Otros fondos propios mil EUR', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_missings']=df.isna().sum(axis=1)\n",
    "x['df_missings_final']= df['n_missings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buscamos los total_funding que son 0\n",
    "print(df[df['total_funding']==0].shape)\n",
    "# cuando el total_funding es 0, el last_funding tambii©n lo imputamos como 0\n",
    "df.loc[df['total_funding']==0, 'last_funding']=0\n",
    "\n",
    "# creamos ratio de last_funding sobre total_funding\n",
    "df['ratio_last_funding']=df['last_funding']/df['total_funding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['total_funding'].describe())\n",
    "print(df['total_funding'].isna().sum())\n",
    "print(df['ratio_last_funding'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacer el calculo de la diferencia entre las variables en el 2020 y 2021 (asi­ se puede sustituir por el valor del 2020)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREACION DE RATIOS EN EL DF completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precio/ventas\n",
    "# precio/ebitda\n",
    "# precio/ebit\n",
    "# precio/benecios (si tienen)\n",
    "# tasa crecimiento ventas\n",
    "# tasa crecimiento ingresos\n",
    "# tasa crecimiento beneficios\n",
    "# ratio de liquidez\n",
    "# ratio de endeudamiento\n",
    "# margen bruto\n",
    "# Cash Burn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Pasivo fijo mil EUR']<0, 'Pasivo fijo mil EUR']=0\n",
    "df.loc[df['Pasivo liquido mil EUR']<0, 'Pasivo liquido mil EUR']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Ratio de liquidez %']=df['Ratio de liquidez %'].fillna(((df['Activo circulante mil EUR'])/(df['Pasivo liquido mil EUR'])))\n",
    "df.loc[:,'Ratio de solvencia %']=df['Ratio de solvencia %'].fillna(df['Ratio de liquidez %'])\n",
    "df.loc[:,'Ratio_endeudamiento']=df['Total pasivo y capital propio mil EUR']/df['Total pasivo']\n",
    "\n",
    "df.loc[:,'Margen_bruto(costes trabajadores)']=(df['Ingresos de explotacion mil EUR']-df['Coste medio de los empleados mil'])/(df['Ingresos de explotacion mil EUR']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se ven cuantas columnas tienen 1 o mas missings\n",
    "print(df.isna().sum()[df.isna().sum()>0].sort_values(ascending=False).count())\n",
    "variables_con_missings= df.isna().sum()[df.isna().sum()>0].sort_values(ascending=False)\n",
    "variables_con_missings_columnas= list(variables_con_missings.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se continua con la imputacion de variables antes de crear nuevos df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se actualiza la lista de variables financieras\n",
    "variables_financieras_eliminadas= ['Resultado Actividades Ordinarias mil EUR', 'Inmovilizado material mil EUR',\n",
    " 'Inmovilizado inmaterial mil EUR', 'Existencias mil EUR', 'Rotacion de las existencias %', \n",
    " 'Dotaciones para amortiz. de inmovil. mil EUR', 'Gastos financieros y gastos asimilados mil EUR', 'Tesoreria mil EUR',\n",
    "  'Otros fondos propios mil EUR']\n",
    "columnas_financieras_completas= columnas_financieras.drop(['year', 'Codigo_NIF', 'n_missings']).drop(variables_financieras_eliminadas)\n",
    "columnas_financieras_completas= columnas_financieras_completas.append(pd.Index(['Total pasivo']))\n",
    "\n",
    "# se divide el valor de la columna en 2021 entre el valor de la columna en 2020\n",
    "# y se calcula la media de crecimiento de cada empresa entre 2020 y 2021 para cada columna financiera y se \n",
    "# guarda en un diccionario y si hay un mi\n",
    "\n",
    "\n",
    "# crecimiento_2020_2021 = {}\n",
    "# for columna in columnas_financieras_completas:\n",
    "#     diff = df.loc[df['year'] == 2021, columna].fillna(0) - df.loc[df['year'] == 2020, columna].fillna(0)\n",
    "#     crecimiento_2020_2021[columna] = np.median(diff)\n",
    "# crecimiento_2020_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antes_nif= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea un for para que si una empresa tiene un missing en una columna financiera en un año, \n",
    "# se sustituye por el del año anterior o posterior\n",
    "\n",
    "for nif in df['Codigo_NIF'].unique():\n",
    "    for columna in variables_con_missings_columnas:\n",
    "        if df.loc[(df['Codigo_NIF']==nif) & (df['year']==2020), columna].isna().values[0]:\n",
    "            df.loc[(df['Codigo_NIF']==nif) & (df['year']==2020), columna]=df.loc[(df['Codigo_NIF']==nif) & (df['year']==2021), columna].values[0]\n",
    "        if df.loc[(df['Codigo_NIF']==nif) & (df['year']==2021), columna].isna().values[0]:\n",
    "            df.loc[(df['Codigo_NIF']==nif) & (df['year']==2021), columna]=df.loc[(df['Codigo_NIF']==nif) & (df['year']==2020), columna].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_eliminar= ['ratio_last_funding','last_round', 'last_funding', 'ownerships', 'Tesoreria mil EUR', 'n_missings' ]\n",
    "df= df.drop(variables_eliminar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuantas empresas tienen las 2 variables missings\n",
    "print((df[(df['Costes de los trabajadores / Ingresos de explotacion (%) %'].isna())&(df['Ingresos de explotacion mil EUR'].isna())]).shape)\n",
    "print((df[(df['Costes de los trabajadores / Ingresos de explotacion (%) %'].isna())&(df['Numero empleados'].isna())]).shape)\n",
    "print((df[(df['Ingresos de explotacion mil EUR'].isna())&(df['Importe neto Cifra de Ventas mil EUR'].isna())]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['growth_stage'].isna(), 'growth_stage']= 0 # se asigna el valor más común\n",
    "df.loc[df['Deudores mil EUR'].isna(), 'Deudores mil EUR']= 0 # se considera que no hay deudores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacion deudas financieras con otras variables\n",
    "df.corr()['Deudas financieras mil EUR'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para imputar coste medio de los empleados, se agrupa por CNAE y se calcula el coste medio\n",
    "df['Codigo primario CNAE adaptado']= df['Codigo primario CNAE 2009'].apply(lambda x: round(x/100,0))\n",
    "df['Coste medio de los empleados mil']=df['Coste medio de los empleados mil'].fillna(df.groupby('Codigo primario CNAE adaptado')['Coste medio de los empleados mil'].transform('median'))\n",
    "df['Costes de los trabajadores / Ingresos de explotacion (%) %']= df['Costes de los trabajadores / Ingresos de explotacion (%) %'].fillna(df.groupby('Codigo primario CNAE 2009')['Costes de los trabajadores / Ingresos de explotacion (%) %'].transform('median'))\n",
    "df['Deudas financieras mil EUR']= df['Deudas financieras mil EUR'].fillna(df.groupby('Codigo primario CNAE 2009')['Deudas financieras mil EUR'].transform('median'))\n",
    "df['Acreedores a L. P. mil EUR']= df['Acreedores a L. P. mil EUR'].fillna(df.groupby('Codigo primario CNAE 2009')['Acreedores a L. P. mil EUR'].transform('median'))\n",
    "df['Acreedores comerciales mil EUR']= df['Acreedores comerciales mil EUR'].fillna(df.groupby('Codigo primario CNAE 2009')['Acreedores comerciales mil EUR'].transform('median'))\n",
    "df['Periodo de cobro (dias) dias']= df['Periodo de cobro (dias) dias'].fillna(df.groupby('Codigo primario CNAE 2009')['Periodo de cobro (dias) dias'].transform('median'))\n",
    "df['Margen de beneficio (%) %']= df['Margen de beneficio (%) %'].fillna(df.groupby('Codigo primario CNAE 2009')['Margen de beneficio (%) %'].transform('median'))\n",
    "df= df.drop('Codigo primario CNAE adaptado', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def imputacion_reg_lineal(df, var_dependiente, var_independiente):\n",
    "    missings = df[df[var_dependiente].isna()]\n",
    "    no_missings = df.dropna(subset=[var_dependiente])\n",
    "\n",
    "    modelo = LinearRegression().fit(no_missings[[var_independiente]], no_missings[var_dependiente])\n",
    "    prediccion = modelo.predict(missings[[var_independiente]])\n",
    "    df.loc[df[var_dependiente].isna(), var_dependiente] = prediccion\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se busca primero la correlacion entre las variables e ingresos de explotacion\n",
    "df.corr()['Ingresos de explotacion mil EUR'].sort_values(ascending=False) # deudores tiene una correlacion muy alta\n",
    "# se imputan los ingresos de explotacion\n",
    "imputacion_reg_lineal(df, 'Ingresos de explotacion mil EUR', 'Deudores mil EUR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Coste medio de los empleados mil']=df['Coste medio de los empleados mil'].fillna(df['Costes de los trabajadores / Ingresos de explotacion (%) %']* df['Ingresos de explotacion mil EUR']/100/df['Numero empleados'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero de empleados\n",
    "df['Numero empleados']=df['Numero empleados'].fillna(round((df['Costes de los trabajadores / Ingresos de explotacion (%) %']* df['Ingresos de explotacion mil EUR']/100/df['Coste medio de los empleados mil']),0))\n",
    "df['Gastos de personal mil EUR']= df['Gastos de personal mil EUR'].fillna(df['Coste medio de los empleados mil']*df['Numero empleados'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea ahora que no hay NAs\n",
    "df.loc[:,'Margen_bruto(costes trabajadores)']=(df['Ingresos de explotacion mil EUR']-df['Coste medio de los empleados mil'])/(df['Ingresos de explotacion mil EUR']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor de total_funding\n",
    "df.corr()['total_funding'].sort_values(ascending=False) # se ve que hay una correlacion con el numero de empleados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importe neto de ventas con ingresos de explotacion\n",
    "imputacion_reg_lineal(df, 'Importe neto Cifra de Ventas mil EUR', 'Ingresos de explotacion mil EUR')\n",
    "# total funding con gastos financieros\n",
    "imputacion_reg_lineal(df, 'Deudas financieras mil EUR', 'Total pasivo')\n",
    "imputacion_reg_lineal(df, 'total_funding', 'Gastos financieros mil EUR')\n",
    "imputacion_reg_lineal(df, 'Acreedores comerciales mil EUR', 'Deudas financieras mil EUR')\n",
    "imputacion_reg_lineal(df, 'Acreedores a L. P. mil EUR', 'Gastos financieros mil EUR')\n",
    "\n",
    "# hay 3 valores de importe neto de ventas que son menores que 0, así que se ponen en positivo\n",
    "df.loc[df['Importe neto Cifra de Ventas mil EUR']<0, 'Importe neto Cifra de Ventas mil EUR']= \\\n",
    "df.loc[df['Importe neto Cifra de Ventas mil EUR']<0, 'Importe neto Cifra de Ventas mil EUR']*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Deudas financieras mil EUR'].describe())\n",
    "print(df[df['Deudas financieras mil EUR']>=0]['Deudas financieras mil EUR'].describe())\n",
    "aa= df[df['Deudas financieras mil EUR']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()[df.isna().sum()>0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se buscan empresas que no coincida la suma de pasivos y fondos propios con el total de activos\n",
    "pasivo_empresas=df[round((df['Total pasivo']+ df['Fondos propios mil EUR']),5)!= round(df['Total activo mil EUR'],5)]\n",
    "df.loc[pasivo_empresas.index, 'Pasivo fijo mil EUR']= (df.loc[pasivo_empresas.index, 'Total activo mil EUR'] - df.loc[pasivo_empresas.index, 'Fondos propios mil EUR']) * 0.47\n",
    "df.loc[pasivo_empresas.index, 'Pasivo liquido mil EUR']= (df.loc[pasivo_empresas.index, 'Total activo mil EUR'] - df.loc[pasivo_empresas.index, 'Fondos propios mil EUR']) * 0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Numero empleados']<=0, 'Numero empleados']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables con outliers\n",
    "sumary= df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Fondos propios mil EUR']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.applymap(lambda x: 99999 if x== np.inf else x)\n",
    "df=df.applymap(lambda x: -99999 if x== -np.inf else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creacion dfs nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivotado= df.pivot_table(index='Codigo_NIF', columns='year', values=columnas_financieras_completas,)\n",
    "df_pivotado_columnas= df_pivotado.columns\n",
    "df_pivotado_copia= df_pivotado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se pasan las columnas de los años de df_pivotado como sufijo de las columnas de df_pivotado\n",
    "df_pivotado.columns= df_pivotado.columns.map('{0[0]}_{0[1]}'.format)\n",
    "df_pivotado= df_pivotado.reset_index()\n",
    "# luego se añaden el resto de columnas de df seleccionando las que no estan en df_pivotado\n",
    "columnas= columnas_financieras_completas.tolist()\n",
    "df_adquisicion_completo= pd.merge(df_pivotado, df.loc[:,~df.columns.isin(columnas)], on= 'Codigo_NIF', how='left')\n",
    "\n",
    "# se quita 1 de cada 2 filas porque hay duplicados\n",
    "df_adquisicion_completo= df_adquisicion_completo.drop_duplicates(subset='Codigo_NIF', keep='first')\n",
    "\n",
    "df_adquisicion_completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea otro df quitando las columnas de 2020\n",
    "df_adquisicion_2021= df_adquisicion_completo.drop(df_adquisicion_completo.filter(regex='_2020').columns, axis=1)\n",
    "df_adquisicion_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se calcula el ratio de crecimiento de las variables financieras entre 2020 y 2021\n",
    "df_pivotado_ratios= pd.DataFrame()\n",
    "for col in df_pivotado_columnas.get_level_values(0):\n",
    "    df_pivotado_ratios[col+'_ratio']=df_pivotado_copia[col][2021]/df_pivotado_copia[col][2020]\n",
    "df_pivotado_ratios= df_pivotado_ratios.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se junta el df de ratios con el df de adquisicion\n",
    "df_adquisicion_final= pd.merge(df_pivotado_ratios,df_adquisicion_2021 , on='Codigo_NIF', how='left')\n",
    "df_adquisicion_final=df_adquisicion_final.applymap(lambda x: 99999 if x== np.inf else x)\n",
    "df_adquisicion_final=df_adquisicion_final.applymap(lambda x: -99999 if x== -np.inf else x)\n",
    "df_adquisicion_final= df_adquisicion_final.fillna(0)\n",
    "df_adquisicion_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graficos= df_adquisicion_final.copy()\n",
    "df_graficos['Localidad']= localidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREACION DEL DATAFRAME **DF Valoracion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero se crea el df que esti© preparado para hacer el modelo de valoracion de empresas\n",
    "# se busca cuando valoracion no es na\n",
    "df_valoracion= df_adquisicion_final[df_adquisicion_final['valuation_2022']!=0]\n",
    "df_valoracion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se quita la columna de valuation\n",
    "df_adquisicion_final= df_adquisicion_final.drop('valuation_2022', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valoracion['Nombre_sabi'].unique().shape # 60 empresas con valoracion\n",
    "# se quita la segunda instancia de cada empresa y se queda con la del 2021\n",
    "df_valoracion= df_valoracion.drop_duplicates(subset='Codigo_NIF', keep='first')\n",
    "df_valoracion= df_valoracion.drop('year', axis=1)\n",
    "df_valoracion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realiza estos calculos si alguna de estas columnas es nula, y sustituye el valor nulo por el calculado\n",
    "df_valoracion.loc[:,'Precio/Venta']=(df_valoracion['valuation_2022']/df_valoracion['Importe neto Cifra de Ventas mil EUR_2021'])\n",
    "df_valoracion.loc[:,'Precio/Ebitda']=(df_valoracion['valuation_2022']/df_valoracion['EBITDA mil EUR_2021'])\n",
    "df_valoracion.loc[:,'Precio/Ebit']=(df_valoracion['valuation_2022']/df_valoracion['EBIT mil EUR_2021'])\n",
    "\n",
    "#Se reemplazan valores infinitos con valores altos.\n",
    "df_valoracion.loc[:,'Precio/Venta']=df_valoracion['Precio/Venta'].replace([np.inf, -np.inf], [99999, -99999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realizan boxplots de las columnas numericas que esten mostradas en %.\n",
    "df_porcentaje = df_valoracion.loc[:, df_valoracion.columns.str.contains('%_2021')]\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.boxplot(data=df_porcentaje, ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_ylim(-500, 500)\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(100))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se saca el codigo_nif de las empresas que tienen mas de 20 missings porque son empresas que no tienen datos para el 2020\n",
    "# y no se pueden calcular los ratios con ellos\n",
    "\n",
    "# empresas_missings= df[df['n_missings']>20]['Codigo_NIF'].unique()\n",
    "# df= df[~df['Codigo_NIF'].isin(empresas_missings)]\n",
    "# print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccion de variables para el modelo de valoracion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos la correlación de la columna 'valuation_2022' con todas las demás columnas\n",
    "correlacion = df_valoracion.corr()['valuation_2022']\n",
    "df_valoracion_correlacion = pd.DataFrame({'Variables': correlacion.index, 'Correlacion con valuation_2022': correlacion.values})\n",
    "df_valoracion_correlacion = df_valoracion_correlacion.sort_values(by='Correlacion con valuation_2022',ascending=False)\n",
    "print(df_valoracion_correlacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos la correlación de la columna 'valuation_2022' con todas las demás columnas, pero en valor absoluto.\n",
    "correlacion = df_valoracion.corr()['valuation_2022']\n",
    "df_valoracion_correlacion_valor_absoluto = pd.DataFrame({'Variables': correlacion.index, 'Correlacion con valuation_2022': correlacion.abs().values})\n",
    "df_valoracion_correlacion_valor_absoluto = df_valoracion_correlacion_valor_absoluto.sort_values(by='Correlacion con valuation_2022', ascending=False)\n",
    "print(df_valoracion_correlacion_valor_absoluto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea la carpeta de datos limpios\n",
    "CARPETA_DATOS_LIMPIOS = 'Datos/Limpios/'\n",
    "if not os.path.exists(CARPETA_DATOS_LIMPIOS):\n",
    "    os.makedirs(CARPETA_DATOS_LIMPIOS)\n",
    "\n",
    "# se guarda el df de adquisicion\n",
    "df_adquisicion_final.to_csv(CARPETA_DATOS_LIMPIOS + 'df_adquisicion_final.csv', index=False)\n",
    "\n",
    "# se guarda el df de valoracion\n",
    "df_valoracion.to_csv(CARPETA_DATOS_LIMPIOS + 'df_valoracion.csv', index=False)\n",
    "\n",
    "# se guarda el df de graficos\n",
    "df_graficos.to_csv(CARPETA_DATOS_LIMPIOS + 'df_graficos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARPETA_DATOS_ORIGINALES = 'Datos/Limpios/'\n",
    "df_adquisicion_final= pd.read_csv(os.path.join(CARPETA_DATOS_ORIGINALES, 'df_adquisicion_final.csv'))\n",
    "df_valoracion= pd.read_csv(os.path.join(CARPETA_DATOS_ORIGINALES, 'df_valoracion.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccion de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valoracion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valoracion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan las variables identificadoras\n",
    "df_valoracion=df_valoracion.drop([\"Codigo_NIF\",'Nombre_sabi'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valoracion_correlacion_valor_absoluto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan las variables que tienen una correlación con 'valuation_2022' menor a 0.3\n",
    "columnas_a_mantener=list(df_valoracion_correlacion_valor_absoluto[df_valoracion_correlacion_valor_absoluto\\\n",
    "    ['Correlacion con valuation_2022']>0.3]['Variables'].values)\n",
    "columnas_a_mantener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valoracion_seleccionado=df_valoracion[columnas_a_mantener]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valoracion_seleccionado=df_valoracion_seleccionado.drop(['valuation_2022'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Seleccionar una lista aleatoria de características para utilizar en el modelo\n",
    "num_features = 10\n",
    "all_features = list(df_valoracion_seleccionado)\n",
    "random.shuffle(all_features)\n",
    "selected_features = all_features[:num_features]\n",
    "\n",
    "# Dividir el conjunto de datos en características y variable objetivo\n",
    "X = df_valoracion[selected_features]\n",
    "y = df_valoracion['valuation_2022']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Entrenar un modelo de regresión lineal utilizando solo las características seleccionadas\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo utilizando el coeficiente de determinación (R^2)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Características utilizadas: {selected_features}, R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Dividir el conjunto de datos en características y variable objetivo\n",
    "X, y = df_valoracion_seleccionado, df_valoracion['valuation_2022']\n",
    "\n",
    "# Iterar a través de diferentes valores de K y seleccionar las mejores características\n",
    "for k in [5, 10, 15]:\n",
    "    # Seleccionar las K mejores características\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    selector.fit(X, y)\n",
    "\n",
    "    # Obtener las características seleccionadas\n",
    "    X_selected = selector.transform(X)\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    # Entrenar un modelo de regresión lineal utilizando solo las características seleccionadas\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluar el rendimiento del modelo utilizando el coeficiente de determinación (R^2)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Para k={k}, R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# # Dividir el conjunto de datos en características y variable objetivo\n",
    "# X, y = df_valoracion_seleccionado, df_valoracion['valuation_2022']\n",
    "\n",
    "# # Crear una lista de todas las combinaciones posibles de características\n",
    "# combinations = []\n",
    "# for k in range(1, len(X.columns) + 1):\n",
    "#     combinations += itertools.combinations(X.columns, k)\n",
    "\n",
    "# # Variables para almacenar la mejor combinación de características y su rendimiento\n",
    "# best_features = None\n",
    "# best_r2 = 0\n",
    "\n",
    "# # Iterar a través de todas las combinaciones posibles de características\n",
    "# for combination in combinations:\n",
    "#     # Seleccionar las características de la combinación actual\n",
    "#     X_subset = X[list(combination)]\n",
    "\n",
    "#     # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, random_state=123)\n",
    "\n",
    "#     # Entrenar un modelo de regresión lineal utilizando solo las características seleccionadas\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Realizar predicciones en el conjunto de prueba\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     # Evaluar el rendimiento del modelo utilizando el coeficiente de determinación (R^2)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#     # Actualizar la mejor combinación de características si el rendimiento es mejor\n",
    "#     if r2 > best_r2:\n",
    "#         best_features = combination\n",
    "#         best_r2 = r2\n",
    "\n",
    "# print(f'Mejor combinación de características: {best_features}, R^2: {best_r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unaimleal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd686aeebece3b8f289d0bac030d29030f2b08a70100b875a45333a0faf38b1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
